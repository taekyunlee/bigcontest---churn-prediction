{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    18295\n",
      "7     8418\n",
      "5     4315\n",
      "8     4270\n",
      "1     1919\n",
      "4     1638\n",
      "3     1075\n",
      "6       57\n",
      "9       12\n",
      "2        1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# train_label데이터는 단일속성이기 때문에 group_by연산이나 EDA시 주의할것\n",
    "# train_trade 형변환 완전히 안해줌!!!\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import mglearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 50) #칼럼 표시개수 설정\n",
    "#pd.set_option('display.max_rows', 100) #로우 표시개수 설정\n",
    "#plt.rcParams['agg.path.chunksize'] = 10000 #그래프 용량\n",
    "#data[data['acc_id'].isin(ne[ne[0] == 2]['acc_id'])] 조건검색\n",
    "\n",
    "# 생존90만 / 이탈60만\n",
    "\n",
    "# rich_monster == boss_monster?? 칼럼명 바뀐건가?\n",
    "# correlation 중복된거 빼고\n",
    "\n",
    "train_activity = pd.read_csv(\"C:/Users/SS/Desktop/data/train_activity.csv\")\n",
    "train_combat = pd.read_csv(\"C:/Users/SS/Desktop/data/train_combat.csv\")\n",
    "train_label = pd.read_csv(\"C:/Users/SS/Desktop/data/train_label.csv\") #일별 평균 결제금액\n",
    "train_payment = pd.read_csv(\"C:/Users/SS/Desktop/data/train_payment.csv\")\n",
    "train_pledge = pd.read_csv(\"C:/Users/SS/Desktop/data/train_pledge.csv\")\n",
    "train_trade = pd.read_csv(\"C:/Users/SS/Desktop/data/train_trade.csv\")\n",
    "\n",
    "test1_activity = pd.read_csv(\"C:/Users/SS/Desktop/data/test1_activity.csv\")\n",
    "test1_combat = pd.read_csv(\"C:/Users/SS/Desktop/data/test1_combat.csv\")\n",
    "test1_payment = pd.read_csv(\"C:/Users/SS/Desktop/data/test1_payment.csv\")\n",
    "test1_pledge = pd.read_csv(\"C:/Users/SS/Desktop/data/test1_pledge.csv\")\n",
    "test1_trade = pd.read_csv(\"C:/Users/SS/Desktop/data/test1_trade.csv\")\n",
    "\n",
    "test2_activity = pd.read_csv(\"C:/Users/SS/Desktop/data/test2_activity.csv\")\n",
    "test2_combat = pd.read_csv(\"C:/Users/SS/Desktop/data/test2_combat.csv\")\n",
    "test2_payment = pd.read_csv(\"C:/Users/SS/Desktop/data/test2_payment.csv\")\n",
    "test2_pledge = pd.read_csv(\"C:/Users/SS/Desktop/data/test2_pledge.csv\")\n",
    "test2_trade = pd.read_csv(\"C:/Users/SS/Desktop/data/test2_trade.csv\")\n",
    "\n",
    "# trade 병합안함\n",
    "train_trade['item_price'].fillna(0 , inplace =True) #교환창거래 == 0.0000\n",
    "\n",
    "train_pledge.rename({'random_attacker_cnt': 'random_attacker_cnt_p', 'random_defender_cnt': 'random_defender_cnt_p', \n",
    "                     'same_pledge_cnt' : 'same_pledge_cnt_p','temp_cnt' : 'temp_cnt_p',  \n",
    "                     'etc_cnt' : 'etc_cnt_p'   }, axis=1, inplace=True) # 겹치는 칼럼명 이름변경\n",
    "\n",
    "train_payment.columns = ['day', 'acc_id', 'day_spent'] # amount_spent의 칼럼 명이 겹치므로 변경, 나중에 test1,2 데이터도 똑같이 변경!\n",
    "\n",
    "m = pd.merge(train_activity, train_label, on = 'acc_id')\n",
    "m = pd.merge(m, train_combat, on = ['day','acc_id','char_id','server'], how = 'left')\n",
    "m = pd.merge(m, train_pledge, on = ['day','acc_id','char_id','server'], how = 'left') \n",
    "m = pd.merge(m, train_payment, on = ['day','acc_id'], how = 'left')\n",
    "data = m\n",
    "\n",
    "#형변환\n",
    "#data['day'] = data['day'].astype(str)\n",
    "data['acc_id'] = data['acc_id'].astype(str)\n",
    "data['char_id'] = data['char_id'].astype(str)\n",
    "data['rich_monster'] = data['rich_monster'].astype(str)\n",
    "data['class'] = data['class'].astype(str)\n",
    "data['level'] = data['level'].astype(str)\n",
    "data['pledge_id'] = data['pledge_id'].astype(str)\n",
    "\n",
    "train_trade['source_acc_id'] = train_trade['source_acc_id'].astype(str)\n",
    "train_trade['target_acc_id'] = train_trade['target_acc_id'].astype(str)\n",
    "train_trade['source_char_id'] = train_trade['source_char_id'].astype(str)\n",
    "train_trade['target_char_id'] = train_trade['target_char_id'].astype(str)\n",
    "\n",
    "# 생존 / 비생존 집단 구분\n",
    "data['suv'] = data['survival_time'].apply(lambda x : 'suv' if x == 64 else 'no_suv')\n",
    "\n",
    "#co = data.groupby('acc_id').sum().reset_index().corr()['amount_spent'] #유저별 변수 합하고나서 survival_time/ amount_spent과의 상관계수\n",
    "#co[co>0.1]\n",
    "\n",
    "#sns.boxplot(x=\"suv\", y=\"playtime\", data=data) #유저별 캐릭터별 play시간 합치지 않고 본것\n",
    "data['day_spent'].fillna(0 , inplace =True) \n",
    "\n",
    "data['pledge_id'] = data['pledge_id'].apply(lambda x : np.nan if x =='nan' else x) #nan에서 진짜 NAN값으로 바꿔주기\n",
    "data['class'] = data['class'].apply(lambda x : np.nan if x =='nan' else x)\n",
    "data['level'] = data['level'].apply(lambda x : np.nan if x =='nan' else x)\n",
    "\n",
    "data['play_char_cnt'].fillna(0 , inplace =True)\n",
    "data['combat_char_cnt'].fillna(0 , inplace =True) \n",
    "data['pledge_combat_cnt'].fillna(0 , inplace =True) \n",
    "data['random_attacker_cnt_p'].fillna(0 , inplace =True) \n",
    "data['random_defender_cnt_p'].fillna(0 , inplace =True) \n",
    "data['same_pledge_cnt_p'].fillna(0 , inplace =True)\n",
    "data['temp_cnt_p'].fillna(0 , inplace =True)\n",
    "data['etc_cnt_p'].fillna(0 , inplace =True)\n",
    "data['combat_play_time'].fillna(0 , inplace =True)\n",
    "data['non_combat_play_time'].fillna(0 , inplace =True)\n",
    "data['pledge_cnt'].fillna(0 , inplace =True)\n",
    "data['random_attacker_cnt'].fillna(0 , inplace =True)\n",
    "data['random_defender_cnt'].fillna(0 , inplace =True)\n",
    "data['non_combat_play_time'].fillna(0 , inplace =True)\n",
    "data['temp_cnt'].fillna(0 , inplace =True)\n",
    "data['same_pledge_cnt'].fillna(0 , inplace =True)\n",
    "data['etc_cnt'].fillna(0 , inplace =True)\n",
    "data['num_opponent'].fillna(0 , inplace =True)\n",
    "\n",
    "#pledge_id가 NAN인 데이터 == 혈맹활동이 없었던 날\n",
    "#data[data['class'].isnull()] -> class, level이 NAN인날 -> 전투활동이 없었던 날\n",
    "\n",
    "#------------------------------------------------------------------------------------\n",
    "# 나중에 할것\n",
    "# play횟수에 따라서 차이나는 생존률 25?26?일부터 suv의 숫자가 no_suv의 숫자보다 많아지기 시작한다.\n",
    "#a= data[['day','acc_id']].drop_duplicates().groupby('acc_id').count().reset_index()\n",
    "#a[a['day'] <2]\n",
    "#data[data['acc_id'].isin(a[a['day'] ==28]['acc_id'])]['suv'].value_counts()\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "li = data.columns.tolist()\n",
    "li.remove('day')\n",
    "li.remove('acc_id')\n",
    "li.remove('char_id')\n",
    "li.remove('server')\n",
    "li.remove('rich_monster')\n",
    "li.remove('class' )\n",
    "li.remove('level')\n",
    "li.remove('pledge_id')\n",
    "li.remove('suv')\n",
    "clus = data\n",
    "\n",
    "x = clus.groupby('acc_id').mean().reset_index()[li].dropna().values #drop_duplicates빼 sum으로 해야하나?\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x) # 데이터 표준화 standardization\n",
    "'''\n",
    "sum = []\n",
    "for i in range(2,20) :\n",
    "    \n",
    "        Kmeans = KMeans(n_clusters = i)\n",
    "        Kmeans.fit(x)\n",
    "\n",
    "        sum.append(Kmeans.inertia_)\n",
    "        \n",
    "plt.plot(sum)\n",
    "'''\n",
    "Kmeans = KMeans(n_clusters = 10 , n_init = 30)\n",
    "Kmeans.fit(x_scaled)\n",
    "\n",
    "clusdata = pd.DataFrame(Kmeans.cluster_centers_)\n",
    "clusdata.rename({0:'playtime', 1:'npc_kill',\n",
    "      2: 'solo_exp', 3: 'party_exp', 4:'quest_exp',5: 'death', 6:'revive',\n",
    "      7: 'exp_recovery',8: 'fishing', 9:'private_shop', 10: 'game_money_change',\n",
    "      11: 'enchant_count',12:'survival_time' , 13:'amount_spent', 14:'pledge_cnt', 15:'random_attacker_cnt', 16:'random_defender_cnt', 17:'temp_cnt', 18:'same_pledge_cnt', 19:'etc_cnt', 20:'num_opponent', 21:'play_char_cnt'\n",
    "                 , 22: 'combat_char_cnt' , 23:'pledge_combat_cnt', 24:'random_attacker_cnt_p', 25:'random_defender_cnt_p',\n",
    "                26:'same_pledge_cnt_p', 27:'temp_cnt_p', 28:'etc_cnt_p', 29:'combat_play_time' ,30:'non_combat_play_time',31:'day_spent',32:'days'}, axis =1 , inplace= True)\n",
    "\n",
    "#print(clusdata)\n",
    "#print()\n",
    "print(pd.Series(Kmeans.labels_).value_counts()) #아웃라이어(비생존) 발견!!!!!!!!!'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clustering = pd.DataFrame(Kmeans.labels_)\n",
    "clustering.rename({0:'mean_clustering'}, axis =1 , inplace = True)\n",
    "\n",
    "li.append('acc_id')\n",
    "anomaly = pd.concat([clus.groupby('acc_id').mean().reset_index()[li].dropna(), clustering] , axis=1 )\n",
    "anomaly[['acc_id','mean_clustering']]\n",
    "\n",
    "ano = pd.merge(data,anomaly[['acc_id','mean_clustering']]).groupby('mean_clustering').mean().reset_index()\n",
    "\n",
    "anomaly_acc_id = anomaly[(anomaly['mean_clustering'] == 2) | (anomaly['mean_clustering'] == 9)]['acc_id'] #이상 군집 제거\n",
    "#anomaly_acc_id\n",
    "\n",
    "#data = data[~(data['acc_id'].isin(anomaly_acc_id))]\n",
    "\n",
    "#plt.figure(figsize = (15,15)) #각 군집별 특징 barplot\n",
    "#for i in ano.columns[2:] :\n",
    "             \n",
    "#             ano[[i]].plot(kind = 'bar',figsize=(10, 5))\n",
    "\n",
    "trade_id = pd.concat([train_trade['source_acc_id'] ,train_trade['target_acc_id']]).drop_duplicates()\n",
    "no_trade_id = data[~(data['acc_id'].isin(trade_id))] #약 6000여명이 거래데이터가 없음 ->거래가 없는 데이터들\n",
    "\n",
    "#no_plege_trade = no_trade_id[no_trade_id['pledge_id'].isnull()] # ->거래x,혈맹x \n",
    "\n",
    "leastpledge = no_trade_id[~(no_trade_id['pledge_id'].isnull())]['acc_id'].drop_duplicates() # 혈맹에 단 한군데도 가입되지 않은 유저 걸러내기, 하나라도 혈맹에 든애들\n",
    "no_trade_pledge = no_trade_id[~(no_trade_id['acc_id'].isin(leastpledge))]\n",
    "\n",
    "# 긴 생존기간 동안 playtime이 3사분위수 이상,사회적 거래x, 혈맹x, 소비x 데이터 삭제\n",
    "outlier = no_trade_pledge.groupby('acc_id').mean().reset_index()\n",
    "outlier = outlier[(outlier['playtime'] > 1.76) & (outlier['npc_kill'] > 0.71) & (outlier['survival_time'] > 60)] #survival_time뺴야겠다.\n",
    "\n",
    "data = data[~(data['acc_id'].isin(outlier['acc_id']))]\n",
    "\n",
    "\n",
    "t = pd.DataFrame(data['acc_id'].isin(trade_id))\n",
    "t = t.rename({'acc_id' : 'trade'} , axis = 1 )\n",
    "t['trade'] = t['trade'].apply(lambda x : 'Y' if x == True else 'N')\n",
    "data = pd.concat([data , t] , axis =1 )\n",
    "\n",
    "# 특정 날 , 특정 서버 , 특정 유저의 상대방에게 주는 아이템의 양과 그에 따른 수익의 합\n",
    "source = train_trade.groupby(['day', 'server','source_acc_id','source_char_id']).sum().reset_index() \n",
    "source = source.rename({'source_acc_id' : 'acc_id', 'source_char_id' : 'char_id', 'item_amount' : 'give_item_amount',\n",
    "              'item_price' : 'revenue_item_price'}, axis =1 )\n",
    "source = source.drop(['type'], axis =1 )\n",
    "\n",
    "data = pd.merge(data, source, on = ['day','server','acc_id','char_id'], how = 'left')\n",
    "\n",
    "# 특정 날 , 특정 서버 , 특정 유저의 상대방에게 받는 아이템의 양과 그에 따른 수익의 합\n",
    "target = train_trade.groupby(['day', 'server','target_acc_id','target_char_id']).sum().reset_index() \n",
    "target = target.rename({'target_acc_id' : 'acc_id', 'target_char_id' : 'char_id', 'item_amount' : 'receive_item_amount',\n",
    "              'item_price' : 'spend_item_price'}, axis =1 )\n",
    "target = target.drop(['type'], axis =1 )\n",
    "\n",
    "data = pd.merge(data, target, on = ['day','server','acc_id','char_id'], how = 'left')\n",
    "\n",
    "#NA값 채워주기\n",
    "\n",
    "data['give_item_amount'].fillna(0, inplace = True) \n",
    "data['receive_item_amount'].fillna(0, inplace = True)\n",
    "\n",
    "data['revenue_item_price'].fillna(0, inplace = True)\n",
    "data['spend_item_price'].fillna(0, inplace = True)\n",
    "\n",
    "#총 거래량\n",
    "data['total_item_amount'] = data['give_item_amount'] + data['receive_item_amount']\n",
    "\n",
    "\n",
    "tem = train_trade.groupby(['day','source_acc_id']).nunique()\n",
    "tem = tem.drop(['source_acc_id','day'], axis = 1 ) #target_acc_id의 수\n",
    "tem = tem.reset_index()\n",
    "\n",
    "tem1 = train_trade.groupby(['day','target_acc_id']).nunique()\n",
    "tem1 = tem1.drop(['target_acc_id','day'], axis = 1 ) #source_acc_id의 수\n",
    "tem1 = tem1.reset_index()\n",
    "\n",
    "tem = tem.rename({'source_acc_id' : 'acc_id'}, axis =1 )[['day','acc_id','target_acc_id']] #target_acc_id의 수\n",
    "tem1 = tem1.rename({'target_acc_id' : 'acc_id'}, axis =1 )[['day','acc_id','source_acc_id']]\n",
    "\n",
    "numkindpartner = pd.merge(tem , tem1 , on = ['day', 'acc_id'], how = 'outer')\n",
    "\n",
    "numkindpartner['target_acc_id'].fillna(0, inplace= True)\n",
    "numkindpartner['source_acc_id'].fillna(0, inplace= True)\n",
    "numkindpartner['total_kind_trade_partner'] = numkindpartner['target_acc_id'] + numkindpartner['source_acc_id']\n",
    "\n",
    "numkindpartner = numkindpartner.groupby('acc_id').var().reset_index()\n",
    "numkindpartner['total_kind_trade_partner'].fillna(0, inplace = True)\n",
    "\n",
    "numkindpartner = numkindpartner.rename({'total_kind_trade_partner' : 'var_kindpartner_day'}, axis =1)\n",
    "numkindpartner = numkindpartner[['acc_id','var_kindpartner_day']]\n",
    "\n",
    "data = pd.merge(data , numkindpartner, on= 'acc_id', how = 'left')\n",
    "data['var_kindpartner_day'].fillna(0 ,inplace = True)\n",
    "\n",
    "\n",
    "give = train_trade.groupby(['day','source_acc_id']).count().reset_index()[['day','source_acc_id','target_acc_id']]\n",
    "take = train_trade.groupby(['day','target_acc_id']).count().reset_index()[['day','target_acc_id','source_acc_id']]\n",
    "\n",
    "give = give.rename({'source_acc_id' : 'acc_id'}, axis =1 )\n",
    "take = take.rename({'target_acc_id' : 'acc_id'}, axis =1 )\n",
    "\n",
    "trade_mean = pd.merge(give , take , on = ['day', 'acc_id'], how = 'outer')\n",
    "trade_mean['target_acc_id'].fillna(0, inplace = True)\n",
    "trade_mean['source_acc_id'].fillna(0, inplace = True)\n",
    "\n",
    "trade_mean['trade_mean'] = trade_mean['target_acc_id'] + trade_mean['source_acc_id']\n",
    "\n",
    "trade_mean = trade_mean.groupby('acc_id').mean().reset_index()[['acc_id','trade_mean']]\n",
    "data = pd.merge(data, trade_mean, on = 'acc_id', how = 'left')\n",
    "data['trade_mean'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "plepar = data.groupby(['day','acc_id']).count().reset_index()[['day','acc_id','pledge_id']]\n",
    "\n",
    "plepar = plepar.groupby('acc_id').sum().reset_index()\n",
    "plepar.rename({'pledge_id' : 'total_parti_pledge'}, axis =1 , inplace = True)\n",
    "plepar = plepar.drop(['day'], axis = 1)\n",
    "\n",
    "data = pd.merge(data , plepar , on= 'acc_id' , how = 'left')\n",
    "\n",
    "'''\n",
    "data1 = data[['acc_id','char_id','server','suv','pledge_id']] # 캐릭터 고려함\n",
    "data1 = data1.drop_duplicates()\n",
    "data1 = data1.dropna(axis = 0)\n",
    "# in - out 으로 생존/이탈 표시  0 = 생존 , 1 = 이탈\n",
    "\n",
    "data1['IN-OUT'] = data1['suv'].apply(lambda x : 1 if x == 'no_suv' else 0)\n",
    "aa = data1.groupby('pledge_id').sum().reset_index() #IN-OUT -> 이탈한 유저의 수\n",
    "bb = data1.groupby('pledge_id').size().to_frame().reset_index().rename({0:'num'} , axis =1 )\n",
    "\n",
    "cc = pd.merge(aa,bb)\n",
    "cc['pledge_churn_ratio'] = cc['IN-OUT'] / cc['num']\n",
    "\n",
    "cc = cc[['pledge_id','pledge_churn_ratio']] # nan / 0.422901 # nan 0으로 처리?????????????????????????????????????\n",
    "cc.loc[21860,'pledge_churn_ratio'] = np.nan                  # 혈맹원수가 극히 적은것들 쳐내야하나??????????????????\n",
    "\n",
    "data = pd.merge(data, cc)'''\n",
    "\n",
    "\n",
    "mean_playtime = data.groupby(['acc_id']).mean().reset_index()[['acc_id','playtime']]\n",
    "mean_playtime.rename({'playtime' : 'mean_playtime'} , axis =1, inplace = True )\n",
    "data = pd.merge(data, mean_playtime, on ='acc_id', how = 'left')\n",
    "\n",
    "\n",
    "pledge_num = data[['acc_id','pledge_id']].drop_duplicates().dropna().groupby('acc_id').count().reset_index()\n",
    "pledge_num.rename({'pledge_id' : 'pledge_num'} , axis =1, inplace = True )\n",
    "data =pd.merge(data, pledge_num, on= 'acc_id' , how = 'left')\n",
    "\n",
    "\n",
    "pledge_size = data[['acc_id','pledge_id']].drop_duplicates().dropna().groupby('pledge_id').count().reset_index()\n",
    "pledge_size.rename({'acc_id' : 'member_num'}, axis= 1 , inplace = True)\n",
    "\n",
    "mem = data[['acc_id','pledge_id']].drop_duplicates().dropna()\n",
    "mem = pd.merge(mem, pledge_size, on ='pledge_id', how = 'left')\n",
    "mem = mem.groupby('acc_id').sum().reset_index()\n",
    "\n",
    "data = pd.merge(data, mem , on='acc_id', how = 'left')\n",
    "\n",
    "data['pledge_num'].fillna(0, inplace= True)\n",
    "data['member_num'].fillna(0, inplace= True)\n",
    "\n",
    "\n",
    "con = data[['day','acc_id']].drop_duplicates() # 얼마나 몰아서 했는가\n",
    "\n",
    "con['Data_lagged'] = con.groupby(['acc_id'])['day'].shift(1)\n",
    "con['diff'] = con['day'] - con['Data_lagged']\n",
    "con.fillna(0 ,inplace= True)\n",
    "\n",
    "con = con[con['diff']<=1]\n",
    "\n",
    "con = con.groupby('acc_id').sum().reset_index()\n",
    "con['ratioConsecutive'] = con['diff'] / 27 # 27?????????????????????????????????????????????????????????????????????\n",
    "con.drop(['day','Data_lagged','diff'], axis =1 , inplace = True)\n",
    "\n",
    "data = pd.merge(data, con, on = ['acc_id'])\n",
    "\n",
    "\n",
    "tot = data.groupby('acc_id').sum().reset_index()\n",
    "tot = tot[['acc_id','playtime']]\n",
    "tot.rename({'playtime' : 'total_playtime'}, axis = 1, inplace= True)\n",
    "\n",
    "data = pd.merge(data, tot, on = ['acc_id'])\n",
    "\n",
    "#sns.boxplot(  y= 'total_playtime' , x= \"suv\", data= data)\n",
    "\n",
    "\n",
    "timedelta = data.groupby(['day','acc_id']).sum().reset_index() # 유저별 캐릭터별 total playtime \n",
    "timedelta = timedelta[['day','acc_id','playtime']]\n",
    "timedelta['day_lagged'] = timedelta.groupby(['acc_id'])['day'].shift(1)\n",
    "timedelta['total_playtime_lagged'] = timedelta.groupby(['acc_id'])['playtime'].shift(1)\n",
    "\n",
    "timedelta['day_diff'] = timedelta['day'] - timedelta['day_lagged']\n",
    "timedelta['playtime_diff'] = timedelta['playtime'] - timedelta['total_playtime_lagged']\n",
    "#.timedelta[timedelta['acc_id'] == '75001']\n",
    "\n",
    "timedelta = timedelta.groupby('acc_id').sum().reset_index()\n",
    "timedelta['total_playtime_changeAve'] = timedelta['playtime_diff'] / timedelta['day_diff']\n",
    "timedelta = timedelta.fillna(0)[['acc_id','total_playtime_changeAve']]\n",
    "\n",
    "data = pd.merge(data, timedelta, on = ['acc_id'])\n",
    "#sns.boxplot(  y= 'total_playtime_changeAve' , x= \"suv\", data= data)\n",
    "\n",
    "# 변화1 + 변화2 + 변화3 / 3\n",
    "\n",
    "'''\n",
    "combatvar = data[['acc_id','pledge_cnt','temp_cnt','same_pledge_cnt','etc_cnt']].groupby('acc_id').var().reset_index()\n",
    "combatvar['combatvar'] = combatvar['pledge_cnt'] + combatvar['temp_cnt'] + combatvar['same_pledge_cnt'] + combatvar['etc_cnt']\n",
    "combatvar = combatvar[['acc_id','combatvar']]\n",
    "\n",
    "data = pd.merge(data, combatvar)'''\n",
    "\n",
    "\n",
    "source_type = train_trade.groupby('source_acc_id').sum().reset_index()[['source_acc_id','type']] #교환창 총 거래횟수\n",
    "target_type = train_trade.groupby('target_acc_id').sum().reset_index()[['target_acc_id','type']]\n",
    "\n",
    "target_type.rename({'target_acc_id' : 'acc_id', 'type' : 'type1'} , axis= 1 , inplace = True)\n",
    "source_type.rename({'source_acc_id' : 'acc_id'} , axis= 1 , inplace = True)\n",
    "\n",
    "exchange = pd.merge(target_type, source_type, on = 'acc_id', how = 'outer')\n",
    "exchange['type'].fillna(0, inplace = True)\n",
    "exchange['type1'].fillna(0, inplace = True)\n",
    "\n",
    "exchange['num_exchange'] = exchange['type1'] + exchange['type']\n",
    "\n",
    "exchange = exchange[['acc_id','num_exchange']]\n",
    "data = pd.merge(data, exchange, on = 'acc_id', how = 'left')\n",
    "data['num_exchange'].fillna(0, inplace = True)\n",
    "\n",
    "################\n",
    "total_source_type = train_trade.groupby('source_acc_id').count().reset_index()[['source_acc_id','type']] #총거래수\n",
    "total_target_type = train_trade.groupby('target_acc_id').count().reset_index()[['target_acc_id','type']]\n",
    "\n",
    "total_target_type.rename({'target_acc_id' : 'acc_id', 'type' : 'type1'} , axis= 1 , inplace = True)\n",
    "total_source_type.rename({'source_acc_id' : 'acc_id'} , axis= 1 , inplace = True)\n",
    "\n",
    "total_trade = pd.merge(total_source_type, total_target_type, on ='acc_id', how = 'outer')\n",
    "total_trade['type'].fillna(0, inplace = True)\n",
    "total_trade['type1'].fillna(0, inplace = True)\n",
    "\n",
    "total_trade['total_trade'] = total_trade['type'] + total_trade['type1']\n",
    "total_trade = total_trade[['acc_id','total_trade']]\n",
    "\n",
    "data = pd.merge(data , total_trade, on='acc_id' , how = 'left')\n",
    "data['total_trade'].fillna(0, inplace = True)\n",
    "\n",
    "data['num_private_shop'] = data['total_trade'] - data['num_exchange'] #개인샵 거래횟수의 총합\n",
    "data['ratio_num_exchange'] = data['num_exchange'] / data['total_trade']   #총 거래중 교환창 거래의 비율 \n",
    "data['ratio_num_private_shop'] = data['num_private_shop'] / data['total_trade'] #총 거래중 개인샵 거래의 비율\n",
    "\n",
    "data['ratio_num_exchange'].fillna(0, inplace = True)\n",
    "data['ratio_num_private_shop'].fillna(0, inplace = True)\n",
    "\n",
    "days = data[['day','acc_id']].drop_duplicates().groupby('acc_id').count().reset_index()\n",
    "days.rename({'day' : 'days'} , axis =1 , inplace = True)\n",
    "data = pd.merge(data, days)\n",
    "\n",
    "\n",
    "# 각 유저마다 특정 혈맹에 연속적으로 참여하는 비율을 구하고 그 비율을 특정혈맹으로 묶어 평균 (특정 혈맹에 연속적으로 참여하는 평균 비율)\n",
    "# 내가 속한 혈맹의 참여율\n",
    "pledgeConsecutive = data[['day','acc_id','pledge_id']].drop_duplicates().dropna() \n",
    "pledgeConsecutive['day_lagged'] = pledgeConsecutive.groupby(['acc_id','pledge_id'])['day'].shift(1)\n",
    "#pledgeConsecutive[(pledgeConsecutive['acc_id'] == '75001') & (pledgeConsecutive['pledge_id'] == '12443.0')]\n",
    "\n",
    "pledgeConsecutive['diff'] = pledgeConsecutive['day'] - pledgeConsecutive['day_lagged']\n",
    "pledgeConsecutive['diff'].fillna(0, inplace = True)\n",
    "pledgeConsecutive = pledgeConsecutive[pledgeConsecutive['diff']<=1]\n",
    "pledgeConsecutive = pledgeConsecutive.groupby(['acc_id','pledge_id']).sum().reset_index()\n",
    "\n",
    "pledgeConsecutive['pledge_ratioConsecutive'] = pledgeConsecutive['diff'] / 27\n",
    "pledgeConsecutive = pledgeConsecutive[['acc_id','pledge_id','pledge_ratioConsecutive']]\n",
    "\n",
    "pledgeConsecutive = pledgeConsecutive.groupby('pledge_id').mean().reset_index()\n",
    "\n",
    "data = pd.merge(data , pledgeConsecutive, on ='pledge_id', how = 'left')\n",
    "\n",
    "mean_pledge_ratioConsecutive = data[['acc_id','pledge_id','pledge_ratioConsecutive']].drop_duplicates().dropna()\n",
    "mean_pledge_ratioConsecutive = mean_pledge_ratioConsecutive.groupby('acc_id').mean().reset_index()\n",
    "\n",
    "mean_pledge_ratioConsecutive.rename({'pledge_ratioConsecutive' : 'mean_pledge_ratioConsecutive'}, axis =1 , inplace = True)\n",
    "data = pd.merge(data , mean_pledge_ratioConsecutive, on ='acc_id', how ='left')\n",
    "data['mean_pledge_ratioConsecutive'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "# 유저당 캐릭터 개수\n",
    "char = data[['acc_id','char_id']].drop_duplicates().groupby('acc_id').count().reset_index()\n",
    "char.rename({'char_id': 'num_char'}, axis =1 , inplace = True)\n",
    "data = pd.merge(data , char , on ='acc_id' , how ='left')\n",
    "\n",
    "#플레이 횟수\n",
    "playnum = data.groupby('acc_id').count().reset_index()[['acc_id','day']]\n",
    "playnum.rename({'day' : 'playnum'} , axis =1 , inplace = True)\n",
    "data = pd.merge(data , playnum , on  = 'acc_id', how = 'left')\n",
    "\n",
    "# 몬스터 타격 횟수\n",
    "data['rich_monster'] = data['rich_monster'].astype(int)\n",
    "\n",
    "rich_monster = data.groupby('acc_id').sum().reset_index()[['acc_id','rich_monster']]\n",
    "rich_monster.rename({'rich_monster' : 'num_rich_monster'}, axis=1 ,inplace = True)\n",
    "data = pd.merge(data, rich_monster , on ='acc_id', how = 'left')\n",
    "\n",
    "\n",
    "# level 변화의 총합\n",
    "\n",
    "data['level'] = data['level'].astype(float)\n",
    "a = data[['acc_id','char_id','level']]\n",
    "level_max = a.groupby(['acc_id','char_id']).max().reset_index()\n",
    "level_max.rename({'level' : 'max_level'} , axis =1 , inplace = True)\n",
    "level_min = a.groupby(['acc_id','char_id']).min().reset_index()\n",
    "level_min.rename({'level' : 'min_level'} , axis =1 , inplace = True)\n",
    "\n",
    "level = pd.merge(level_max, level_min, on =['acc_id','char_id']) \n",
    "level['level_change'] = level['max_level'] - level['min_level']\n",
    "level = level[['acc_id','char_id','level_change']]\n",
    "level = level.groupby('acc_id').sum().reset_index()\n",
    "\n",
    "data = pd.merge(data, level, on ='acc_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestData1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test1_trade['item_price'].fillna(0 , inplace =True) #교환창거래 == 0.0000\n",
    "\n",
    "test1_pledge.rename({'random_attacker_cnt': 'random_attacker_cnt_p', 'random_defender_cnt': 'random_defender_cnt_p', \n",
    "                     'same_pledge_cnt' : 'same_pledge_cnt_p','temp_cnt' : 'temp_cnt_p',  \n",
    "                     'etc_cnt' : 'etc_cnt_p'   }, axis=1, inplace=True) # 겹치는 칼럼명 이름변경\n",
    "\n",
    "test1_payment.columns = ['day', 'acc_id', 'day_spent'] # amount_spent의 칼럼 명이 겹치므로 변경, 나중에 test1,2 데이터도 똑같이 변경!\n",
    "\n",
    "#m = pd.merge(train_activity, train_label, on = 'acc_id')\n",
    "m = pd.merge(test1_activity , test1_combat, on = ['day','acc_id','char_id','server'], how = 'left')\n",
    "m = pd.merge(m, test1_pledge, on = ['day','acc_id','char_id','server'], how = 'left') \n",
    "m = pd.merge(m, test1_payment, on = ['day','acc_id'], how = 'left')\n",
    "testdata1 = m\n",
    "\n",
    "#형변환\n",
    "#data['day'] = data['day'].astype(str)\n",
    "testdata1['acc_id'] = testdata1['acc_id'].astype(str)\n",
    "testdata1['char_id'] = testdata1['char_id'].astype(str)\n",
    "testdata1['rich_monster'] = testdata1['rich_monster'].astype(str)\n",
    "testdata1['class'] = testdata1['class'].astype(str)\n",
    "testdata1['level'] = testdata1['level'].astype(str)\n",
    "testdata1['pledge_id'] = testdata1['pledge_id'].astype(str)\n",
    "\n",
    "test1_trade['source_acc_id'] = test1_trade['source_acc_id'].astype(str)\n",
    "test1_trade['target_acc_id'] = test1_trade['target_acc_id'].astype(str)\n",
    "test1_trade['source_char_id'] = test1_trade['source_char_id'].astype(str)\n",
    "test1_trade['target_char_id'] = test1_trade['target_char_id'].astype(str)\n",
    "\n",
    "# 생존 / 비생존 집단 구분\n",
    "#data['suv'] = data['survival_time'].apply(lambda x : 'suv' if x == 64 else 'no_suv')\n",
    "\n",
    "#co = data.groupby('acc_id').sum().reset_index().corr()['amount_spent'] #유저별 변수 합하고나서 survival_time/ amount_spent과의 상관계수\n",
    "#co[co>0.1]\n",
    "\n",
    "#sns.boxplot(x=\"suv\", y=\"playtime\", data=data) #유저별 캐릭터별 play시간 합치지 않고 본것\n",
    "testdata1['day_spent'].fillna(0 , inplace =True) \n",
    "\n",
    "testdata1['pledge_id'] = testdata1['pledge_id'].apply(lambda x : np.nan if x =='nan' else x) #nan에서 진짜 NAN값으로 바꿔주기\n",
    "testdata1['class'] = testdata1['class'].apply(lambda x : np.nan if x =='nan' else x)\n",
    "testdata1['level'] = testdata1['level'].apply(lambda x : np.nan if x =='nan' else x)\n",
    "\n",
    "testdata1['play_char_cnt'].fillna(0 , inplace =True)\n",
    "testdata1['combat_char_cnt'].fillna(0 , inplace =True) \n",
    "testdata1['pledge_combat_cnt'].fillna(0 , inplace =True) \n",
    "testdata1['random_attacker_cnt_p'].fillna(0 , inplace =True) \n",
    "testdata1['random_defender_cnt_p'].fillna(0 , inplace =True) \n",
    "testdata1['same_pledge_cnt_p'].fillna(0 , inplace =True)\n",
    "testdata1['temp_cnt_p'].fillna(0 , inplace =True)\n",
    "testdata1['etc_cnt_p'].fillna(0 , inplace =True)\n",
    "testdata1['combat_play_time'].fillna(0 , inplace =True)\n",
    "testdata1['non_combat_play_time'].fillna(0 , inplace =True)\n",
    "testdata1['pledge_cnt'].fillna(0 , inplace =True)\n",
    "testdata1['random_attacker_cnt'].fillna(0 , inplace =True)\n",
    "testdata1['random_defender_cnt'].fillna(0 , inplace =True)\n",
    "testdata1['non_combat_play_time'].fillna(0 , inplace =True)\n",
    "testdata1['temp_cnt'].fillna(0 , inplace =True)\n",
    "testdata1['same_pledge_cnt'].fillna(0 , inplace =True)\n",
    "testdata1['etc_cnt'].fillna(0 , inplace =True)\n",
    "testdata1['num_opponent'].fillna(0 , inplace =True)\n",
    "\n",
    "\n",
    "\n",
    "#days\n",
    "days = testdata1[['day','acc_id']].drop_duplicates().groupby('acc_id').count().reset_index()\n",
    "days.rename({'day' : 'days'} , axis =1 , inplace = True)\n",
    "testdata1 = pd.merge(testdata1, days)\n",
    "\n",
    "\n",
    "'''\n",
    "trade_id = pd.concat([test1_trade['source_acc_id'] ,test1_trade['target_acc_id']]).drop_duplicates()\n",
    "no_trade_id = testdata1[~(testdata1['acc_id'].isin(trade_id))] #약 6000여명이 거래데이터가 없음 ->거래가 없는 데이터들\n",
    "\n",
    "#no_plege_trade = no_trade_id[no_trade_id['pledge_id'].isnull()] # ->거래x,혈맹x \n",
    "\n",
    "leastpledge = no_trade_id[~(no_trade_id['pledge_id'].isnull())]['acc_id'].drop_duplicates() # 혈맹에 단 한군데도 가입되지 않은 유저 걸러내기, 하나라도 혈맹에 든애들\n",
    "no_trade_pledge = no_trade_id[~(no_trade_id['acc_id'].isin(leastpledge))]\n",
    "\n",
    "# 긴 생존기간 동안 playtime이 3사분위수 이상,사회적 거래x, 혈맹x, 소비x 데이터 삭제\n",
    "outlier = no_trade_pledge.groupby('acc_id').mean().reset_index()\n",
    "outlier = outlier[(outlier['playtime'] > 2.35) & (outlier['npc_kill'] > 0.39) ]\n",
    "\n",
    "testdata1 = testdata1[~(testdata1['acc_id'].isin(outlier['acc_id']))]'''\n",
    "\n",
    "\n",
    "# 거래유무 변수\n",
    "t = pd.DataFrame(testdata1['acc_id'].isin(trade_id))\n",
    "t = t.rename({'acc_id' : 'trade'} , axis = 1 )\n",
    "t['trade'] = t['trade'].apply(lambda x : 'Y' if x == True else 'N')\n",
    "testdata1 = pd.concat([testdata1 , t] , axis =1 )\n",
    "\n",
    "\n",
    "# 특정 날 , 특정 서버 , 특정 유저의 상대방에게 주는 아이템의 양과 그에 따른 수익의 합\n",
    "source = test1_trade.groupby(['day', 'server','source_acc_id','source_char_id']).sum().reset_index() \n",
    "source = source.rename({'source_acc_id' : 'acc_id', 'source_char_id' : 'char_id', 'item_amount' : 'give_item_amount',\n",
    "              'item_price' : 'revenue_item_price'}, axis =1 )\n",
    "source = source.drop(['type'], axis =1 )\n",
    "\n",
    "testdata1 = pd.merge(testdata1, source, on = ['day','server','acc_id','char_id'], how = 'left')\n",
    "\n",
    "# 특정 날 , 특정 서버 , 특정 유저의 상대방에게 받는 아이템의 양과 그에 따른 수익의 합\n",
    "target = test1_trade.groupby(['day', 'server','target_acc_id','target_char_id']).sum().reset_index() \n",
    "target = target.rename({'target_acc_id' : 'acc_id', 'target_char_id' : 'char_id', 'item_amount' : 'receive_item_amount',\n",
    "              'item_price' : 'spend_item_price'}, axis =1 )\n",
    "target = target.drop(['type'], axis =1 )\n",
    "\n",
    "testdata1 = pd.merge(testdata1, target, on = ['day','server','acc_id','char_id'], how = 'left')\n",
    "\n",
    "#NA값 채워주기\n",
    "\n",
    "testdata1['give_item_amount'].fillna(0, inplace = True) \n",
    "testdata1['receive_item_amount'].fillna(0, inplace = True)\n",
    "\n",
    "testdata1['revenue_item_price'].fillna(0, inplace = True)\n",
    "testdata1['spend_item_price'].fillna(0, inplace = True)\n",
    "\n",
    "#총 거래량\n",
    "testdata1['total_item_amount'] = testdata1['give_item_amount'] + testdata1['receive_item_amount']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tem = test1_trade.groupby(['day','source_acc_id']).nunique()\n",
    "tem = tem.drop(['source_acc_id','day'], axis = 1 ) #target_acc_id의 수\n",
    "tem = tem.reset_index()\n",
    "\n",
    "tem1 = test1_trade.groupby(['day','target_acc_id']).nunique()\n",
    "tem1 = tem1.drop(['target_acc_id','day'], axis = 1 ) #source_acc_id의 수\n",
    "tem1 = tem1.reset_index()\n",
    "\n",
    "tem = tem.rename({'source_acc_id' : 'acc_id'}, axis =1 )[['day','acc_id','target_acc_id']] #target_acc_id의 수\n",
    "tem1 = tem1.rename({'target_acc_id' : 'acc_id'}, axis =1 )[['day','acc_id','source_acc_id']]\n",
    "\n",
    "numkindpartner = pd.merge(tem , tem1 , on = ['day', 'acc_id'], how = 'outer')\n",
    "\n",
    "numkindpartner['target_acc_id'].fillna(0, inplace= True)\n",
    "numkindpartner['source_acc_id'].fillna(0, inplace= True)\n",
    "numkindpartner['total_kind_trade_partner'] = numkindpartner['target_acc_id'] + numkindpartner['source_acc_id']\n",
    "\n",
    "numkindpartner = numkindpartner.groupby('acc_id').var().reset_index()\n",
    "numkindpartner['total_kind_trade_partner'].fillna(0, inplace = True)\n",
    "\n",
    "numkindpartner = numkindpartner.rename({'total_kind_trade_partner' : 'var_kindpartner_day'}, axis =1)\n",
    "numkindpartner = numkindpartner[['acc_id','var_kindpartner_day']]\n",
    "\n",
    "testdata1 = pd.merge(testdata1 , numkindpartner, on= 'acc_id', how = 'left')\n",
    "testdata1['var_kindpartner_day'].fillna(0 ,inplace = True)\n",
    "\n",
    "#######################\n",
    "give = test1_trade.groupby(['day','source_acc_id']).count().reset_index()[['day','source_acc_id','target_acc_id']]\n",
    "take = test1_trade.groupby(['day','target_acc_id']).count().reset_index()[['day','target_acc_id','source_acc_id']]\n",
    "\n",
    "give = give.rename({'source_acc_id' : 'acc_id'}, axis =1 )\n",
    "take = take.rename({'target_acc_id' : 'acc_id'}, axis =1 )\n",
    "\n",
    "trade_mean = pd.merge(give , take , on = ['day', 'acc_id'], how = 'outer')\n",
    "trade_mean['target_acc_id'].fillna(0, inplace = True)\n",
    "trade_mean['source_acc_id'].fillna(0, inplace = True)\n",
    "\n",
    "trade_mean['trade_mean'] = trade_mean['target_acc_id'] + trade_mean['source_acc_id']\n",
    "\n",
    "trade_mean = trade_mean.groupby('acc_id').mean().reset_index()[['acc_id','trade_mean']]\n",
    "testdata1 = pd.merge(testdata1, trade_mean, on = 'acc_id', how = 'left')\n",
    "testdata1['trade_mean'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "############################\n",
    "plepar = testdata1.groupby(['day','acc_id']).count().reset_index()[['day','acc_id','pledge_id']]\n",
    "\n",
    "plepar = plepar.groupby('acc_id').sum().reset_index()\n",
    "plepar.rename({'pledge_id' : 'total_parti_pledge'}, axis =1 , inplace = True)\n",
    "plepar = plepar.drop(['day'], axis = 1)\n",
    "\n",
    "testdata1 = pd.merge(testdata1 , plepar , on= 'acc_id' , how = 'left')\n",
    "#######################\n",
    "\n",
    "mean_playtime = testdata1.groupby(['acc_id']).mean().reset_index()[['acc_id','playtime']]\n",
    "mean_playtime.rename({'playtime' : 'mean_playtime'} , axis =1, inplace = True )\n",
    "testdata1 = pd.merge(testdata1, mean_playtime, on ='acc_id', how = 'left')\n",
    "\n",
    "\n",
    "\n",
    "##########\n",
    "pledge_num = testdata1[['acc_id','pledge_id']].drop_duplicates().dropna().groupby('acc_id').count().reset_index()\n",
    "pledge_num.rename({'pledge_id' : 'pledge_num'} , axis =1, inplace = True )\n",
    "testdata1 =pd.merge(testdata1, pledge_num, on= 'acc_id' , how = 'left')\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "pledge_size = testdata1[['acc_id','pledge_id']].drop_duplicates().dropna().groupby('pledge_id').count().reset_index()\n",
    "pledge_size.rename({'acc_id' : 'member_num'}, axis= 1 , inplace = True)\n",
    "\n",
    "mem = testdata1[['acc_id','pledge_id']].drop_duplicates().dropna()\n",
    "mem = pd.merge(mem, pledge_size, on ='pledge_id', how = 'left')\n",
    "mem = mem.groupby('acc_id').sum().reset_index()\n",
    "\n",
    "testdata1 = pd.merge(testdata1, mem , on='acc_id', how = 'left')\n",
    "\n",
    "testdata1['pledge_num'].fillna(0, inplace= True)\n",
    "testdata1['member_num'].fillna(0, inplace= True)\n",
    "\n",
    "\n",
    "\n",
    "con = testdata1[['day','acc_id']].drop_duplicates() # 얼마나 몰아서 했는가\n",
    "\n",
    "con['Data_lagged'] = con.groupby(['acc_id'])['day'].shift(1)\n",
    "con['diff'] = con['day'] - con['Data_lagged']\n",
    "con.fillna(0 ,inplace= True)\n",
    "\n",
    "con = con[con['diff']<=1]\n",
    "\n",
    "con = con.groupby('acc_id').sum().reset_index()\n",
    "con['ratioConsecutive'] = con['diff'] / 27 # 27?????????????????????????????????????????????????????????????????????\n",
    "con.drop(['day','Data_lagged','diff'], axis =1 , inplace = True)\n",
    "\n",
    "testdata1 = pd.merge(testdata1, con, on = ['acc_id'])\n",
    "\n",
    "\n",
    "tot = testdata1.groupby('acc_id').sum().reset_index()\n",
    "tot = tot[['acc_id','playtime']]\n",
    "tot.rename({'playtime' : 'total_playtime'}, axis = 1, inplace= True)\n",
    "\n",
    "testdata1 = pd.merge(testdata1, tot, on = ['acc_id'])\n",
    "\n",
    "#sns.boxplot(  y= 'total_playtime' , x= \"suv\", data= data)\n",
    "\n",
    "\n",
    "timedelta = testdata1.groupby(['day','acc_id']).sum().reset_index() # 유저별 캐릭터별 total playtime \n",
    "timedelta = timedelta[['day','acc_id','playtime']]\n",
    "timedelta['day_lagged'] = timedelta.groupby(['acc_id'])['day'].shift(1)\n",
    "timedelta['total_playtime_lagged'] = timedelta.groupby(['acc_id'])['playtime'].shift(1)\n",
    "\n",
    "timedelta['day_diff'] = timedelta['day'] - timedelta['day_lagged']\n",
    "timedelta['playtime_diff'] = timedelta['playtime'] - timedelta['total_playtime_lagged']\n",
    "#.timedelta[timedelta['acc_id'] == '75001']\n",
    "\n",
    "timedelta = timedelta.groupby('acc_id').sum().reset_index()\n",
    "timedelta['total_playtime_changeAve'] = timedelta['playtime_diff'] / timedelta['day_diff']\n",
    "timedelta = timedelta.fillna(0)[['acc_id','total_playtime_changeAve']]\n",
    "\n",
    "testdata1 = pd.merge(testdata1, timedelta, on = ['acc_id'])\n",
    "#sns.boxplot(  y= 'total_playtime_changeAve' , x= \"suv\", data= data)\n",
    "\n",
    "# 변화1 + 변화2 + 변화3 / 3\n",
    "\n",
    "'''\n",
    "combatvar = testdata1[['acc_id','pledge_cnt','temp_cnt','same_pledge_cnt','etc_cnt']].groupby('acc_id').var().reset_index()\n",
    "combatvar['combatvar'] = combatvar['pledge_cnt'] + combatvar['temp_cnt'] + combatvar['same_pledge_cnt'] + combatvar['etc_cnt']\n",
    "combatvar = combatvar[['acc_id','combatvar']]\n",
    "\n",
    "testdata1 = pd.merge(testdata1, combatvar)'''\n",
    "\n",
    "\n",
    "source_type = test1_trade.groupby('source_acc_id').sum().reset_index()[['source_acc_id','type']] #교환창을 통한 총 거래횟수\n",
    "target_type = test1_trade.groupby('target_acc_id').sum().reset_index()[['target_acc_id','type']]\n",
    "\n",
    "target_type.rename({'target_acc_id' : 'acc_id', 'type' : 'type1'} , axis= 1 , inplace = True)\n",
    "source_type.rename({'source_acc_id' : 'acc_id'} , axis= 1 , inplace = True)\n",
    "\n",
    "exchange = pd.merge(target_type, source_type, on = 'acc_id', how = 'outer')\n",
    "exchange['type'].fillna(0, inplace = True)\n",
    "exchange['type1'].fillna(0, inplace = True)\n",
    "\n",
    "exchange['num_exchange'] = exchange['type1'] + exchange['type']\n",
    "\n",
    "exchange = exchange[['acc_id','num_exchange']]\n",
    "testdata1 = pd.merge(testdata1, exchange, on = 'acc_id', how = 'left')\n",
    "testdata1['num_exchange'].fillna(0, inplace = True)\n",
    "\n",
    "total_source_type = test1_trade.groupby('source_acc_id').count().reset_index()[['source_acc_id','type']]\n",
    "total_target_type = test1_trade.groupby('target_acc_id').count().reset_index()[['target_acc_id','type']]\n",
    "\n",
    "total_target_type.rename({'target_acc_id' : 'acc_id', 'type' : 'type1'} , axis= 1 , inplace = True)\n",
    "total_source_type.rename({'source_acc_id' : 'acc_id'} , axis= 1 , inplace = True)\n",
    "\n",
    "total_trade = pd.merge(total_source_type, total_target_type, on ='acc_id', how = 'outer')\n",
    "total_trade['type'].fillna(0, inplace = True)\n",
    "total_trade['type1'].fillna(0, inplace = True)\n",
    "\n",
    "total_trade['total_trade'] = total_trade['type'] + total_trade['type1']\n",
    "total_trade = total_trade[['acc_id','total_trade']]\n",
    "\n",
    "testdata1 = pd.merge(testdata1 , total_trade, on='acc_id' , how = 'left')\n",
    "testdata1['total_trade'].fillna(0, inplace = True)\n",
    "\n",
    "testdata1['num_private_shop'] = testdata1['total_trade'] - testdata1['num_exchange']\n",
    "testdata1['ratio_num_exchange'] = testdata1['num_exchange'] / testdata1['total_trade']\n",
    "testdata1['ratio_num_private_shop'] = testdata1['num_private_shop'] / testdata1['total_trade']\n",
    "\n",
    "testdata1['ratio_num_exchange'].fillna(0, inplace = True)\n",
    "testdata1['ratio_num_private_shop'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "# 각 유저마다 특정 혈맹에 연속적으로 참여하는 비율을 구하고 그 비율을 특정혈맹으로 묶어 평균 (특정 혈맹에 연속적으로 참여하는 평균 비율)\n",
    "# 내가 속한 혈맹의 참여율\n",
    "pledgeConsecutive = testdata1[['day','acc_id','pledge_id']].drop_duplicates().dropna() \n",
    "pledgeConsecutive['day_lagged'] = pledgeConsecutive.groupby(['acc_id','pledge_id'])['day'].shift(1)\n",
    "#pledgeConsecutive[(pledgeConsecutive['acc_id'] == '75001') & (pledgeConsecutive['pledge_id'] == '12443.0')]\n",
    "\n",
    "pledgeConsecutive['diff'] = pledgeConsecutive['day'] - pledgeConsecutive['day_lagged']\n",
    "pledgeConsecutive['diff'].fillna(0, inplace = True)\n",
    "pledgeConsecutive = pledgeConsecutive[pledgeConsecutive['diff']<=1]\n",
    "pledgeConsecutive = pledgeConsecutive.groupby(['acc_id','pledge_id']).sum().reset_index()\n",
    "\n",
    "pledgeConsecutive['pledge_ratioConsecutive'] = pledgeConsecutive['diff'] / 27\n",
    "pledgeConsecutive = pledgeConsecutive[['acc_id','pledge_id','pledge_ratioConsecutive']]\n",
    "\n",
    "pledgeConsecutive = pledgeConsecutive.groupby('pledge_id').mean().reset_index()\n",
    "\n",
    "testdata1 = pd.merge(testdata1 , pledgeConsecutive, on ='pledge_id', how = 'left')\n",
    "\n",
    "mean_pledge_ratioConsecutive = testdata1[['acc_id','pledge_id','pledge_ratioConsecutive']].drop_duplicates().dropna()\n",
    "mean_pledge_ratioConsecutive = mean_pledge_ratioConsecutive.groupby('acc_id').mean().reset_index()\n",
    "\n",
    "mean_pledge_ratioConsecutive.rename({'pledge_ratioConsecutive' : 'mean_pledge_ratioConsecutive'}, axis =1 , inplace = True)\n",
    "testdata1 = pd.merge(testdata1 , mean_pledge_ratioConsecutive, on ='acc_id', how ='left')\n",
    "testdata1['mean_pledge_ratioConsecutive'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "# 유저당 캐릭터 개수\n",
    "char = testdata1[['acc_id','char_id']].drop_duplicates().groupby('acc_id').count().reset_index()\n",
    "char.rename({'char_id': 'num_char'}, axis =1 , inplace = True)\n",
    "testdata1 = pd.merge(testdata1 , char , on ='acc_id' , how ='left')\n",
    "\n",
    "\n",
    "#플레이 횟수\n",
    "playnum = testdata1.groupby('acc_id').count().reset_index()[['acc_id','day']]\n",
    "playnum.rename({'day' : 'playnum'} , axis =1 , inplace = True)\n",
    "testdata1 = pd.merge(testdata1 , playnum , on  = 'acc_id', how = 'left')\n",
    "\n",
    "# 몬스토 타격 횟수\n",
    "testdata1['rich_monster'] = testdata1['rich_monster'].astype(int)\n",
    "\n",
    "rich_monster = testdata1.groupby('acc_id').sum().reset_index()[['acc_id','rich_monster']]\n",
    "rich_monster.rename({'rich_monster' : 'num_rich_monster'}, axis=1 ,inplace = True)\n",
    "testdata1 = pd.merge(testdata1, rich_monster , on ='acc_id', how = 'left')\n",
    "\n",
    "\n",
    "# level 변화의 총합\n",
    "\n",
    "data['level'] = data['level'].astype(float)\n",
    "a = data[['acc_id','char_id','level']]\n",
    "level_max = a.groupby(['acc_id','char_id']).max().reset_index()\n",
    "level_max.rename({'level' : 'max_level'} , axis =1 , inplace = True)\n",
    "level_min = a.groupby(['acc_id','char_id']).min().reset_index()\n",
    "level_min.rename({'level' : 'min_level'} , axis =1 , inplace = True)\n",
    "\n",
    "level = pd.merge(level_max, level_min, on =['acc_id','char_id']) \n",
    "level['level_change'] = level['max_level'] - level['min_level']\n",
    "level = level[['acc_id','char_id','level_change']]\n",
    "level = level.groupby('acc_id').sum().reset_index()\n",
    "\n",
    "data = pd.merge(data, level, on ='acc_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2_trade['item_price'].fillna(0 , inplace =True) #교환창거래 == 0.0000\n",
    "\n",
    "test2_pledge.rename({'random_attacker_cnt': 'random_attacker_cnt_p', 'random_defender_cnt': 'random_defender_cnt_p', \n",
    "                     'same_pledge_cnt' : 'same_pledge_cnt_p','temp_cnt' : 'temp_cnt_p',  \n",
    "                     'etc_cnt' : 'etc_cnt_p'   }, axis=1, inplace=True) # 겹치는 칼럼명 이름변경\n",
    "\n",
    "test2_payment.columns = ['day', 'acc_id', 'day_spent'] # amount_spent의 칼럼 명이 겹치므로 변경, 나중에 test1,2 데이터도 똑같이 변경!\n",
    "\n",
    "#m = pd.merge(train_activity, train_label, on = 'acc_id')\n",
    "m = pd.merge(test2_activity , test2_combat, on = ['day','acc_id','char_id','server'], how = 'left')\n",
    "m = pd.merge(m, test2_pledge, on = ['day','acc_id','char_id','server'], how = 'left') \n",
    "m = pd.merge(m, test2_payment, on = ['day','acc_id'], how = 'left')\n",
    "testdata2 = m\n",
    "\n",
    "#형변환\n",
    "#data['day'] = data['day'].astype(str)\n",
    "testdata2['acc_id'] = testdata2['acc_id'].astype(str)\n",
    "testdata2['char_id'] = testdata2['char_id'].astype(str)\n",
    "testdata2['rich_monster'] = testdata2['rich_monster'].astype(str)\n",
    "testdata2['class'] = testdata2['class'].astype(str)\n",
    "testdata2['level'] = testdata2['level'].astype(str)\n",
    "testdata2['pledge_id'] = testdata2['pledge_id'].astype(str)\n",
    "\n",
    "test2_trade['source_acc_id'] = test2_trade['source_acc_id'].astype(str)\n",
    "test2_trade['target_acc_id'] = test2_trade['target_acc_id'].astype(str)\n",
    "test2_trade['source_char_id'] = test2_trade['source_char_id'].astype(str)\n",
    "test2_trade['target_char_id'] = test2_trade['target_char_id'].astype(str)\n",
    "\n",
    "# 생존 / 비생존 집단 구분\n",
    "#data['suv'] = data['survival_time'].apply(lambda x : 'suv' if x == 64 else 'no_suv')\n",
    "\n",
    "#co = data.groupby('acc_id').sum().reset_index().corr()['amount_spent'] #유저별 변수 합하고나서 survival_time/ amount_spent과의 상관계수\n",
    "#co[co>0.1]\n",
    "\n",
    "#sns.boxplot(x=\"suv\", y=\"playtime\", data=data) #유저별 캐릭터별 play시간 합치지 않고 본것\n",
    "testdata2['day_spent'].fillna(0 , inplace =True) \n",
    "\n",
    "testdata2['pledge_id'] = testdata2['pledge_id'].apply(lambda x : np.nan if x =='nan' else x) #nan에서 진짜 NAN값으로 바꿔주기\n",
    "testdata2['class'] = testdata2['class'].apply(lambda x : np.nan if x =='nan' else x)\n",
    "testdata2['level'] = testdata2['level'].apply(lambda x : np.nan if x =='nan' else x)\n",
    "\n",
    "testdata2['play_char_cnt'].fillna(0 , inplace =True)\n",
    "testdata2['combat_char_cnt'].fillna(0 , inplace =True) \n",
    "testdata2['pledge_combat_cnt'].fillna(0 , inplace =True) \n",
    "testdata2['random_attacker_cnt_p'].fillna(0 , inplace =True) \n",
    "testdata2['random_defender_cnt_p'].fillna(0 , inplace =True) \n",
    "testdata2['same_pledge_cnt_p'].fillna(0 , inplace =True)\n",
    "testdata2['temp_cnt_p'].fillna(0 , inplace =True)\n",
    "testdata2['etc_cnt_p'].fillna(0 , inplace =True)\n",
    "testdata2['combat_play_time'].fillna(0 , inplace =True)\n",
    "testdata2['non_combat_play_time'].fillna(0 , inplace =True)\n",
    "testdata2['pledge_cnt'].fillna(0 , inplace =True)\n",
    "testdata2['random_attacker_cnt'].fillna(0 , inplace =True)\n",
    "testdata2['random_defender_cnt'].fillna(0 , inplace =True)\n",
    "testdata2['non_combat_play_time'].fillna(0 , inplace =True)\n",
    "testdata2['temp_cnt'].fillna(0 , inplace =True)\n",
    "testdata2['same_pledge_cnt'].fillna(0 , inplace =True)\n",
    "testdata2['etc_cnt'].fillna(0 , inplace =True)\n",
    "testdata2['num_opponent'].fillna(0 , inplace =True)\n",
    "\n",
    "\n",
    "#days\n",
    "days = testdata2[['day','acc_id']].drop_duplicates().groupby('acc_id').count().reset_index()\n",
    "days.rename({'day' : 'days'} , axis =1 , inplace = True)\n",
    "testdata2 = pd.merge(testdata2, days)\n",
    "\n",
    "\n",
    "'''\n",
    "trade_id = pd.concat([test2_trade['source_acc_id'] ,test2_trade['target_acc_id']]).drop_duplicates()\n",
    "no_trade_id = testdata2[~(testdata2['acc_id'].isin(trade_id))] #약 6000여명이 거래데이터가 없음 ->거래가 없는 데이터들\n",
    "\n",
    "#no_plege_trade = no_trade_id[no_trade_id['pledge_id'].isnull()] # ->거래x,혈맹x \n",
    "\n",
    "leastpledge = no_trade_id[~(no_trade_id['pledge_id'].isnull())]['acc_id'].drop_duplicates() # 혈맹에 단 한군데도 가입되지 않은 유저 걸러내기, 하나라도 혈맹에 든애들\n",
    "no_trade_pledge = no_trade_id[~(no_trade_id['acc_id'].isin(leastpledge))]\n",
    "\n",
    "# 긴 생존기간 동안 playtime이 3사분위수 이상,사회적 거래x, 혈맹x, 소비x 데이터 삭제\n",
    "outlier = no_trade_pledge.groupby('acc_id').mean().reset_index()\n",
    "outlier = outlier[(outlier['playtime'] > 2.35) & (outlier['npc_kill'] > 0.39) ]\n",
    "\n",
    "testdata2 = testdata2[~(testdata2['acc_id'].isin(outlier['acc_id']))]'''\n",
    "\n",
    "\n",
    "# 거래유무 변수\n",
    "t = pd.DataFrame(testdata2['acc_id'].isin(trade_id))\n",
    "t = t.rename({'acc_id' : 'trade'} , axis = 1 )\n",
    "t['trade'] = t['trade'].apply(lambda x : 'Y' if x == True else 'N')\n",
    "testdata2 = pd.concat([testdata2 , t] , axis =1 )\n",
    "\n",
    "\n",
    "# 특정 날 , 특정 서버 , 특정 유저의 상대방에게 주는 아이템의 양과 그에 따른 수익의 합\n",
    "source = test2_trade.groupby(['day', 'server','source_acc_id','source_char_id']).sum().reset_index() \n",
    "source = source.rename({'source_acc_id' : 'acc_id', 'source_char_id' : 'char_id', 'item_amount' : 'give_item_amount',\n",
    "              'item_price' : 'revenue_item_price'}, axis =1 )\n",
    "source = source.drop(['type'], axis =1 )\n",
    "\n",
    "testdata2 = pd.merge(testdata2, source, on = ['day','server','acc_id','char_id'], how = 'left')\n",
    "\n",
    "# 특정 날 , 특정 서버 , 특정 유저의 상대방에게 받는 아이템의 양과 그에 따른 수익의 합\n",
    "target = test2_trade.groupby(['day', 'server','target_acc_id','target_char_id']).sum().reset_index() \n",
    "target = target.rename({'target_acc_id' : 'acc_id', 'target_char_id' : 'char_id', 'item_amount' : 'receive_item_amount',\n",
    "              'item_price' : 'spend_item_price'}, axis =1 )\n",
    "target = target.drop(['type'], axis =1 )\n",
    "\n",
    "testdata2 = pd.merge(testdata2, target, on = ['day','server','acc_id','char_id'], how = 'left')\n",
    "\n",
    "#NA값 채워주기\n",
    "\n",
    "testdata2['give_item_amount'].fillna(0, inplace = True) \n",
    "testdata2['receive_item_amount'].fillna(0, inplace = True)\n",
    "\n",
    "testdata2['revenue_item_price'].fillna(0, inplace = True)\n",
    "testdata2['spend_item_price'].fillna(0, inplace = True)\n",
    "\n",
    "#총 거래량\n",
    "testdata2['total_item_amount'] = testdata2['give_item_amount'] + testdata2['receive_item_amount']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tem = test2_trade.groupby(['day','source_acc_id']).nunique()\n",
    "tem = tem.drop(['source_acc_id','day'], axis = 1 ) #target_acc_id의 수\n",
    "tem = tem.reset_index()\n",
    "\n",
    "tem1 = test2_trade.groupby(['day','target_acc_id']).nunique()\n",
    "tem1 = tem1.drop(['target_acc_id','day'], axis = 1 ) #source_acc_id의 수\n",
    "tem1 = tem1.reset_index()\n",
    "\n",
    "tem = tem.rename({'source_acc_id' : 'acc_id'}, axis =1 )[['day','acc_id','target_acc_id']] #target_acc_id의 수\n",
    "tem1 = tem1.rename({'target_acc_id' : 'acc_id'}, axis =1 )[['day','acc_id','source_acc_id']]\n",
    "\n",
    "numkindpartner = pd.merge(tem , tem1 , on = ['day', 'acc_id'], how = 'outer')\n",
    "\n",
    "numkindpartner['target_acc_id'].fillna(0, inplace= True)\n",
    "numkindpartner['source_acc_id'].fillna(0, inplace= True)\n",
    "numkindpartner['total_kind_trade_partner'] = numkindpartner['target_acc_id'] + numkindpartner['source_acc_id']\n",
    "\n",
    "numkindpartner = numkindpartner.groupby('acc_id').var().reset_index()\n",
    "numkindpartner['total_kind_trade_partner'].fillna(0, inplace = True)\n",
    "\n",
    "numkindpartner = numkindpartner.rename({'total_kind_trade_partner' : 'var_kindpartner_day'}, axis =1)\n",
    "numkindpartner = numkindpartner[['acc_id','var_kindpartner_day']]\n",
    "\n",
    "testdata2 = pd.merge(testdata2 , numkindpartner, on= 'acc_id', how = 'left')\n",
    "testdata2['var_kindpartner_day'].fillna(0 ,inplace = True)\n",
    "\n",
    "#######################\n",
    "give = test2_trade.groupby(['day','source_acc_id']).count().reset_index()[['day','source_acc_id','target_acc_id']]\n",
    "take = test2_trade.groupby(['day','target_acc_id']).count().reset_index()[['day','target_acc_id','source_acc_id']]\n",
    "\n",
    "give = give.rename({'source_acc_id' : 'acc_id'}, axis =1 )\n",
    "take = take.rename({'target_acc_id' : 'acc_id'}, axis =1 )\n",
    "\n",
    "trade_mean = pd.merge(give , take , on = ['day', 'acc_id'], how = 'outer')\n",
    "trade_mean['target_acc_id'].fillna(0, inplace = True)\n",
    "trade_mean['source_acc_id'].fillna(0, inplace = True)\n",
    "\n",
    "trade_mean['trade_mean'] = trade_mean['target_acc_id'] + trade_mean['source_acc_id']\n",
    "\n",
    "trade_mean = trade_mean.groupby('acc_id').mean().reset_index()[['acc_id','trade_mean']]\n",
    "testdata2 = pd.merge(testdata2, trade_mean, on = 'acc_id', how = 'left')\n",
    "testdata2['trade_mean'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "############################\n",
    "plepar = testdata2.groupby(['day','acc_id']).count().reset_index()[['day','acc_id','pledge_id']]\n",
    "\n",
    "plepar = plepar.groupby('acc_id').sum().reset_index()\n",
    "plepar.rename({'pledge_id' : 'total_parti_pledge'}, axis =1 , inplace = True)\n",
    "plepar = plepar.drop(['day'], axis = 1)\n",
    "\n",
    "testdata2 = pd.merge(testdata2 , plepar , on= 'acc_id' , how = 'left')\n",
    "#######################\n",
    "\n",
    "mean_playtime = testdata2.groupby(['acc_id']).mean().reset_index()[['acc_id','playtime']]\n",
    "mean_playtime.rename({'playtime' : 'mean_playtime'} , axis =1, inplace = True )\n",
    "testdata2 = pd.merge(testdata2, mean_playtime, on ='acc_id', how = 'left')\n",
    "\n",
    "\n",
    "\n",
    "##########\n",
    "pledge_num = testdata2[['acc_id','pledge_id']].drop_duplicates().dropna().groupby('acc_id').count().reset_index()\n",
    "pledge_num.rename({'pledge_id' : 'pledge_num'} , axis =1, inplace = True )\n",
    "testdata2 =pd.merge(testdata2, pledge_num, on= 'acc_id' , how = 'left')\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "pledge_size = testdata2[['acc_id','pledge_id']].drop_duplicates().dropna().groupby('pledge_id').count().reset_index()\n",
    "pledge_size.rename({'acc_id' : 'member_num'}, axis= 1 , inplace = True)\n",
    "\n",
    "mem = testdata2[['acc_id','pledge_id']].drop_duplicates().dropna()\n",
    "mem = pd.merge(mem, pledge_size, on ='pledge_id', how = 'left')\n",
    "mem = mem.groupby('acc_id').sum().reset_index()\n",
    "\n",
    "testdata2 = pd.merge(testdata2, mem , on='acc_id', how = 'left')\n",
    "\n",
    "testdata2['pledge_num'].fillna(0, inplace= True)\n",
    "testdata2['member_num'].fillna(0, inplace= True)\n",
    "\n",
    "\n",
    "con = testdata2[['day','acc_id']].drop_duplicates() # 얼마나 몰아서 했는가\n",
    "\n",
    "con['Data_lagged'] = con.groupby(['acc_id'])['day'].shift(1)\n",
    "con['diff'] = con['day'] - con['Data_lagged']\n",
    "con.fillna(0 ,inplace= True)\n",
    "\n",
    "con = con[con['diff']<=1]\n",
    "\n",
    "con = con.groupby('acc_id').sum().reset_index()\n",
    "con['ratioConsecutive'] = con['diff'] / 27 # 27?????????????????????????????????????????????????????????????????????\n",
    "con.drop(['day','Data_lagged','diff'], axis =1 , inplace = True)\n",
    "\n",
    "testdata2 = pd.merge(testdata2, con, on = ['acc_id'])\n",
    "\n",
    "\n",
    "tot = testdata2.groupby('acc_id').sum().reset_index()\n",
    "tot = tot[['acc_id','playtime']]\n",
    "tot.rename({'playtime' : 'total_playtime'}, axis = 1, inplace= True)\n",
    "\n",
    "testdata2 = pd.merge(testdata2, tot, on = ['acc_id'])\n",
    "\n",
    "#sns.boxplot(  y= 'total_playtime' , x= \"suv\", data= data)\n",
    "\n",
    "\n",
    "timedelta = testdata2.groupby(['day','acc_id']).sum().reset_index() # 유저별 캐릭터별 total playtime \n",
    "timedelta = timedelta[['day','acc_id','playtime']]\n",
    "timedelta['day_lagged'] = timedelta.groupby(['acc_id'])['day'].shift(1)\n",
    "timedelta['total_playtime_lagged'] = timedelta.groupby(['acc_id'])['playtime'].shift(1)\n",
    "\n",
    "timedelta['day_diff'] = timedelta['day'] - timedelta['day_lagged']\n",
    "timedelta['playtime_diff'] = timedelta['playtime'] - timedelta['total_playtime_lagged']\n",
    "#.timedelta[timedelta['acc_id'] == '75001']\n",
    "\n",
    "timedelta = timedelta.groupby('acc_id').sum().reset_index()\n",
    "timedelta['total_playtime_changeAve'] = timedelta['playtime_diff'] / timedelta['day_diff']\n",
    "timedelta = timedelta.fillna(0)[['acc_id','total_playtime_changeAve']]\n",
    "\n",
    "testdata2 = pd.merge(testdata2, timedelta, on = ['acc_id'])\n",
    "#sns.boxplot(  y= 'total_playtime_changeAve' , x= \"suv\", data= data)\n",
    "\n",
    "# 변화1 + 변화2 + 변화3 / 3\n",
    "\n",
    "'''\n",
    "combatvar = testdata2[['acc_id','pledge_cnt','temp_cnt','same_pledge_cnt','etc_cnt']].groupby('acc_id').var().reset_index()\n",
    "combatvar['combatvar'] = combatvar['pledge_cnt'] + combatvar['temp_cnt'] + combatvar['same_pledge_cnt'] + combatvar['etc_cnt']\n",
    "combatvar = combatvar[['acc_id','combatvar']]\n",
    "\n",
    "testdata2 = pd.merge(testdata2, combatvar)'''\n",
    "\n",
    "\n",
    "source_type = test2_trade.groupby('source_acc_id').sum().reset_index()[['source_acc_id','type']]\n",
    "target_type = test2_trade.groupby('target_acc_id').sum().reset_index()[['target_acc_id','type']]\n",
    "\n",
    "target_type.rename({'target_acc_id' : 'acc_id', 'type' : 'type1'} , axis= 1 , inplace = True)\n",
    "source_type.rename({'source_acc_id' : 'acc_id'} , axis= 1 , inplace = True)\n",
    "\n",
    "exchange = pd.merge(target_type, source_type, on = 'acc_id', how = 'outer')\n",
    "exchange['type'].fillna(0, inplace = True)\n",
    "exchange['type1'].fillna(0, inplace = True)\n",
    "\n",
    "exchange['num_exchange'] = exchange['type1'] + exchange['type']\n",
    "\n",
    "exchange = exchange[['acc_id','num_exchange']]\n",
    "testdata2 = pd.merge(testdata2, exchange, on = 'acc_id', how = 'left')\n",
    "testdata2['num_exchange'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "total_source_type = test2_trade.groupby('source_acc_id').count().reset_index()[['source_acc_id','type']]\n",
    "total_target_type = test2_trade.groupby('target_acc_id').count().reset_index()[['target_acc_id','type']]\n",
    "\n",
    "total_target_type.rename({'target_acc_id' : 'acc_id', 'type' : 'type1'} , axis= 1 , inplace = True)\n",
    "total_source_type.rename({'source_acc_id' : 'acc_id'} , axis= 1 , inplace = True)\n",
    "\n",
    "total_trade = pd.merge(total_source_type, total_target_type, on ='acc_id', how = 'outer')\n",
    "total_trade['type'].fillna(0, inplace = True)\n",
    "total_trade['type1'].fillna(0, inplace = True)\n",
    "\n",
    "total_trade['total_trade'] = total_trade['type'] + total_trade['type1']\n",
    "total_trade = total_trade[['acc_id','total_trade']]\n",
    "\n",
    "testdata2 = pd.merge(testdata2 , total_trade, on='acc_id' , how = 'left')\n",
    "testdata2['total_trade'].fillna(0, inplace = True)\n",
    "\n",
    "testdata2['num_private_shop'] = testdata2['total_trade'] - testdata2['num_exchange']\n",
    "testdata2['ratio_num_exchange'] = testdata2['num_exchange'] / testdata2['total_trade']\n",
    "testdata2['ratio_num_private_shop'] = testdata2['num_private_shop'] / testdata2['total_trade']\n",
    "\n",
    "testdata2['ratio_num_exchange'].fillna(0, inplace = True)\n",
    "testdata2['ratio_num_private_shop'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "# 각 유저마다 특정 혈맹에 연속적으로 참여하는 비율을 구하고 그 비율을 특정혈맹으로 묶어 평균 (특정 혈맹에 연속적으로 참여하는 평균 비율)\n",
    "# 내가 속한 혈맹의 참여율\n",
    "pledgeConsecutive = testdata2[['day','acc_id','pledge_id']].drop_duplicates().dropna() \n",
    "pledgeConsecutive['day_lagged'] = pledgeConsecutive.groupby(['acc_id','pledge_id'])['day'].shift(1)\n",
    "#pledgeConsecutive[(pledgeConsecutive['acc_id'] == '75001') & (pledgeConsecutive['pledge_id'] == '12443.0')]\n",
    "\n",
    "pledgeConsecutive['diff'] = pledgeConsecutive['day'] - pledgeConsecutive['day_lagged']\n",
    "pledgeConsecutive['diff'].fillna(0, inplace = True)\n",
    "pledgeConsecutive = pledgeConsecutive[pledgeConsecutive['diff']<=1]\n",
    "pledgeConsecutive = pledgeConsecutive.groupby(['acc_id','pledge_id']).sum().reset_index()\n",
    "\n",
    "pledgeConsecutive['pledge_ratioConsecutive'] = pledgeConsecutive['diff'] / 27\n",
    "pledgeConsecutive = pledgeConsecutive[['acc_id','pledge_id','pledge_ratioConsecutive']]\n",
    "\n",
    "pledgeConsecutive = pledgeConsecutive.groupby('pledge_id').mean().reset_index()\n",
    "\n",
    "testdata2 = pd.merge(testdata2 , pledgeConsecutive, on ='pledge_id', how = 'left')\n",
    "\n",
    "mean_pledge_ratioConsecutive = testdata2[['acc_id','pledge_id','pledge_ratioConsecutive']].drop_duplicates().dropna()\n",
    "mean_pledge_ratioConsecutive = mean_pledge_ratioConsecutive.groupby('acc_id').mean().reset_index()\n",
    "\n",
    "mean_pledge_ratioConsecutive.rename({'pledge_ratioConsecutive' : 'mean_pledge_ratioConsecutive'}, axis =1 , inplace = True)\n",
    "testdata2 = pd.merge(testdata2 , mean_pledge_ratioConsecutive, on ='acc_id', how ='left')\n",
    "testdata2['mean_pledge_ratioConsecutive'].fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "# 유저당 캐릭터 개수\n",
    "char = testdata2[['acc_id','char_id']].drop_duplicates().groupby('acc_id').count().reset_index()\n",
    "char.rename({'char_id': 'num_char'}, axis =1 , inplace = True)\n",
    "testdata2 = pd.merge(testdata2 , char , on ='acc_id' , how ='left')\n",
    "\n",
    "\n",
    "#플레이 횟수\n",
    "playnum = testdata2.groupby('acc_id').count().reset_index()[['acc_id','day']]\n",
    "playnum.rename({'day' : 'playnum'} , axis =1 , inplace = True)\n",
    "testdata2 = pd.merge(testdata2 , playnum , on  = 'acc_id', how = 'left')\n",
    "\n",
    "#몬스터 타격 횟수\n",
    "testdata2['rich_monster'] = testdata2['rich_monster'].astype(int)\n",
    "\n",
    "rich_monster = testdata2.groupby('acc_id').sum().reset_index()[['acc_id','rich_monster']]\n",
    "rich_monster.rename({'rich_monster' : 'num_rich_monster'}, axis=1 ,inplace = True)\n",
    "testdata2 = pd.merge(testdata2, rich_monster , on ='acc_id', how = 'left')\n",
    "\n",
    "\n",
    "# level 변화의 총합\n",
    "\n",
    "testdata2['level'] = testdata2['level'].astype(float)\n",
    "a = testdata2[['acc_id','char_id','level']]\n",
    "level_max = a.groupby(['acc_id','char_id']).max().reset_index()\n",
    "level_max.rename({'level' : 'max_level'} , axis =1 , inplace = True)\n",
    "level_min = a.groupby(['acc_id','char_id']).min().reset_index()\n",
    "level_min.rename({'level' : 'min_level'} , axis =1 , inplace = True)\n",
    "\n",
    "level = pd.merge(level_max, level_min, on =['acc_id','char_id']) \n",
    "level['level_change'] = level['max_level'] - level['min_level']\n",
    "level = level[['acc_id','char_id','level_change']]\n",
    "level = level.groupby('acc_id').sum().reset_index()\n",
    "\n",
    "testdata2 = pd.merge(testdata2, level, on ='acc_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['survival_time' 'amount_spent' 'level_change_x' 'level_change_y'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-3a9258528bb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mnew_testdata1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mnew_testdata2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\SS\\Anaconda31\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\SS\\Anaconda31\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2175\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2176\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2177\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2178\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\SS\\Anaconda31\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1267\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1269\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['survival_time' 'amount_spent' 'level_change_x' 'level_change_y'] not in index\""
     ]
    }
   ],
   "source": [
    "lst = data.columns.tolist()\n",
    "lst2 = data.columns.tolist()\n",
    "#playtime solo_exp quest_exp fishing private_shop pledge_cnt play_char_cnt revenue_item_price  trade_mean total_parti_pledge \n",
    "#mean_playtime ratioConsecutive total_playtime   num_exchange total_trade ratio_num_private_shop  days pledge_ratioConsecutive\n",
    "#playnum\n",
    "nouse = ['day',\n",
    "  'class','level','rich_monster',\n",
    " 'char_id',\n",
    " 'server',\n",
    " 'pledge_ratioConsecutive',\n",
    "\n",
    "\n",
    " \n",
    " 'pledge_id',\n",
    "  'suv']\n",
    "\n",
    "for i in nouse :\n",
    "        lst.remove(i)\n",
    "        \n",
    "nouse2 = ['day',\n",
    " 'class','level','rich_monster',\n",
    " 'char_id',\n",
    " 'server',\n",
    " 'pledge_ratioConsecutive',\n",
    " \n",
    " 'pledge_id',\n",
    "  'suv']\n",
    "\n",
    "for i in nouse2 :\n",
    "        lst2.remove(i)\n",
    "        \n",
    "data['acc_id'] = data['acc_id'].astype(int)\n",
    "testdata1['acc_id'] = testdata1['acc_id'].astype(int)\n",
    "testdata2['acc_id'] = testdata2['acc_id'].astype(int)\n",
    "\n",
    "new_data = pd.get_dummies(data[lst])\n",
    "new_testdata1 = pd.get_dummies(testdata1[lst])\n",
    "new_testdata2 = pd.get_dummies(testdata2[lst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "suv_train_x = new_data.groupby('acc_id').mean().reset_index()[lst].values                 #mean학습\n",
    "suv_train_y = new_data.groupby(['acc_id']).mean().reset_index()['survival_time'].values\n",
    "\n",
    "spen_train_x = new_data.groupby('acc_id').mean().reset_index()[lst2].values\n",
    "spen_train_y = new_data.groupby(['acc_id']).mean().reset_index()['amount_spent'].values\n",
    "\n",
    "\n",
    "test_su_x1= new_testdata1.groupby(['acc_id']).mean().reset_index()[lst].values\n",
    "test_su_x2= new_testdata2.groupby(['acc_id']).mean().reset_index()[lst].values\n",
    "\n",
    "test_sp_x1= new_testdata1.groupby(['acc_id']).mean().reset_index()[lst2].values\n",
    "test_sp_x2= new_testdata2.groupby(['acc_id']).mean().reset_index()[lst2].values\n",
    "\n",
    "\n",
    "\n",
    "suv_lr = xgb.XGBRegressor(booster='gbtree', eta = 0.1, min_child_weight =5,\n",
    "                          max_depth = 5, gamma = 0 , alpha = 5, n_estimators=200).fit(suv_train_x,suv_train_y)\n",
    "\n",
    "spen_lr = xgb.XGBRegressor(booster='gbtree', eta = 0.1, min_child_weight =5,\n",
    "                          max_depth = 5, gamma = 0 , alpha = 5, n_estimators=200).fit(spen_train_x,spen_train_y)\n",
    "\n",
    "\n",
    "su = suv_lr.predict(test_su_x1)\n",
    "sp = spen_lr.predict(test_sp_x1)\n",
    "\n",
    "su2 = suv_lr.predict(test_su_x2)\n",
    "sp2 = spen_lr.predict(test_sp_x2)\n",
    "\n",
    "ccc = testdata1.groupby('acc_id').mean().reset_index()[['acc_id']]\n",
    "\n",
    "aaa = pd.DataFrame(su)\n",
    "aaa.rename({0: 'survival_time'}, axis =1 , inplace = True)\n",
    "\n",
    "bbb = pd.DataFrame(sp)\n",
    "bbb.rename({0: 'amount_spent'}, axis =1 , inplace = True)\n",
    "\n",
    "file1 = pd.concat([ccc,aaa,bbb], axis =1 )\n",
    "\n",
    "\n",
    "ddd = testdata2.groupby('acc_id').mean().reset_index()[['acc_id']]\n",
    "\n",
    "aaa2 = pd.DataFrame(su2)\n",
    "aaa2.rename({0: 'survival_time'}, axis =1 , inplace = True)\n",
    "\n",
    "bbb2 = pd.DataFrame(sp2)\n",
    "bbb2.rename({0: 'amount_spent'}, axis =1 , inplace = True)\n",
    "\n",
    "file2 = pd.concat([ddd,aaa2,bbb2], axis =1 )\n",
    "\n",
    "file1['amount_spent'] = file1['amount_spent'].apply(lambda x : 0 if x<0 else x)\n",
    "file2['amount_spent'] = file2['amount_spent'].apply(lambda x : 0 if x<0 else x)\n",
    "\n",
    "file1['survival_time'] = file1['survival_time'].apply(lambda x : 1 if x<1 else x)\n",
    "file2['survival_time'] = file2['survival_time'].apply(lambda x : 1 if x<1 else x)\n",
    "\n",
    "\n",
    "file1.to_csv('C:/Users/SS/Desktop/test1_predict.csv' ,header= True, index= False, encoding='UTF-8')\n",
    "\n",
    "file2.to_csv('C:/Users/SS/Desktop/test2_predict.csv' ,header= True, index= False, encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lst = data.columns.tolist()\n",
    "lst2 = data.columns.tolist()\n",
    "#playtime solo_exp quest_exp fishing private_shop pledge_cnt play_char_cnt revenue_item_price  trade_mean total_parti_pledge \n",
    "#mean_playtime ratioConsecutive total_playtime   num_exchange total_trade ratio_num_private_shop  days pledge_ratioConsecutive\n",
    "#playnum\n",
    "nouse = ['day',\n",
    " 'acc_id',\n",
    " 'char_id',\n",
    " 'server',\n",
    " \n",
    " 'npc_kill',\n",
    " \n",
    " 'party_exp',\n",
    " \n",
    " 'rich_monster',\n",
    " 'death',\n",
    " 'revive',\n",
    " 'exp_recovery',\n",
    " \n",
    " \n",
    " 'game_money_change',\n",
    " 'enchant_count',\n",
    " 'survival_time',\n",
    " 'amount_spent',\n",
    " 'class',\n",
    " 'level',\n",
    " \n",
    " 'random_attacker_cnt',\n",
    " 'random_defender_cnt',\n",
    " 'temp_cnt',\n",
    " 'same_pledge_cnt',\n",
    " 'etc_cnt',\n",
    " 'num_opponent',\n",
    " 'pledge_id',\n",
    " \n",
    " 'combat_char_cnt',\n",
    " 'pledge_combat_cnt',\n",
    " 'random_attacker_cnt_p',\n",
    " 'random_defender_cnt_p',\n",
    " 'same_pledge_cnt_p',\n",
    " 'temp_cnt_p',\n",
    " 'etc_cnt_p',\n",
    " 'combat_play_time',\n",
    " 'non_combat_play_time',\n",
    " 'day_spent',\n",
    " 'suv',\n",
    " 'trade',\n",
    " 'give_item_amount',\n",
    " \n",
    " 'receive_item_amount',\n",
    " 'spend_item_price',\n",
    " 'total_item_amount',\n",
    " 'var_kindpartner_day',\n",
    "\n",
    " \n",
    "\n",
    " 'pledge_num',\n",
    " 'member_num',\n",
    " \n",
    " \n",
    " 'total_playtime_changeAve',\n",
    " \n",
    " \n",
    " 'num_private_shop',\n",
    " 'ratio_num_exchange',\n",
    " \n",
    " \n",
    " \n",
    " 'mean_pledge_ratioConsecutive',\n",
    " 'num_char']\n",
    "\n",
    "for i in nouse :\n",
    "        lst.remove(i)\n",
    "        \n",
    "nouse2 = ['private_shop',\n",
    " 'random_defender_cnt',\n",
    " 'party_exp',\n",
    " 'combat_char_cnt',\n",
    " 'pledge_num',\n",
    " 'ratio_num_private_shop',\n",
    " 'temp_cnt',\n",
    " 'enchant_count',\n",
    " 'revive',\n",
    " 'exp_recovery',\n",
    " 'mean_playtime', 'day', 'acc_id','char_id', 'server','rich_monster','pledge_id' ,'suv' ,'trade','pledge_ratioConsecutive' ,'class', 'level','survival_time','amount_spent']\n",
    "\n",
    "for i in nouse2 :\n",
    "        lst2.remove(i)\n",
    "        \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "suv_train_x = data.groupby(['acc_id']).mean().reset_index()[lst].values                 #mean학습\n",
    "suv_train_y = data.groupby(['acc_id']).mean().reset_index()['survival_time'].values\n",
    "\n",
    "spen_train_x = data.groupby(['acc_id']).mean().reset_index()[lst2].values\n",
    "spen_train_y = data.groupby(['acc_id']).mean().reset_index()['amount_spent'].values\n",
    " \n",
    "#suv_train_x = data[lst].values                      #그냥 다 학습\n",
    "#suv_train_y = data['survival_time'].values\n",
    "\n",
    "#spen_train_x = data.groupby('acc_id').mean().reset_index()[lst].values\n",
    "#spen_train_y = data.groupby('acc_id').mean().reset_index()['amount_spent'].values\n",
    "\n",
    "\n",
    "test_su_x1= testdata1.groupby(['acc_id']).mean().reset_index()[lst].values\n",
    "test_su_x2= testdata2.groupby(['acc_id']).mean().reset_index()[lst].values\n",
    "\n",
    "test_sp_x1= testdata1.groupby(['acc_id']).mean().reset_index()[lst2].values\n",
    "test_sp_x2= testdata2.groupby(['acc_id']).mean().reset_index()[lst2].values\n",
    "\n",
    "#suv_lr = RandomForestRegressor(n_estimators = 100).fit(suv_train_x, suv_train_y)\n",
    "#spen_lr = RandomForestRegressor(n_estimators = 100).fit(spen_train_x, spen_train_y)\n",
    "\n",
    "suv_lr = xgb.XGBRegressor(booster='gbtree', eta = 0.1, min_child_weight =5,\n",
    "                          max_depth = 5, gamma = 0 , alpha = 5, n_estimators=200).fit(suv_train_x,suv_train_y)\n",
    "\n",
    "spen_lr = xgb.XGBRegressor(booster='gbtree', eta = 0.1, min_child_weight =5,\n",
    "                          max_depth = 5, gamma = 0 , alpha = 5, n_estimators=200).fit(spen_train_x,spen_train_y)\n",
    "\n",
    "\n",
    "su = suv_lr.predict(test_su_x1)\n",
    "sp = spen_lr.predict(test_sp_x1)\n",
    "\n",
    "su2 = suv_lr.predict(test_su_x2)\n",
    "sp2 = spen_lr.predict(test_sp_x2)\n",
    "\n",
    "ccc = testdata1.groupby('acc_id').mean().reset_index()[['acc_id']]\n",
    "\n",
    "aaa = pd.DataFrame(su)\n",
    "aaa.rename({0: 'survival_time'}, axis =1 , inplace = True)\n",
    "\n",
    "bbb = pd.DataFrame(sp)\n",
    "bbb.rename({0: 'amount_spent'}, axis =1 , inplace = True)\n",
    "\n",
    "file1 = pd.concat([ccc,aaa,bbb], axis =1 )\n",
    "\n",
    "\n",
    "ddd = testdata2.groupby('acc_id').mean().reset_index()[['acc_id']]\n",
    "\n",
    "aaa2 = pd.DataFrame(su2)\n",
    "aaa2.rename({0: 'survival_time'}, axis =1 , inplace = True)\n",
    "\n",
    "bbb2 = pd.DataFrame(sp2)\n",
    "bbb2.rename({0: 'amount_spent'}, axis =1 , inplace = True)\n",
    "\n",
    "file2 = pd.concat([ddd,aaa2,bbb2], axis =1 )\n",
    "\n",
    "file1['amount_spent'] = file1['amount_spent'].apply(lambda x : 0 if x<0 else x)\n",
    "file2['amount_spent'] = file2['amount_spent'].apply(lambda x : 0 if x<0 else x)\n",
    "\n",
    "file1['survival_time'] = file1['survival_time'].apply(lambda x : 1 if x<1 else x)\n",
    "file2['survival_time'] = file2['survival_time'].apply(lambda x : 1 if x<1 else x)\n",
    "\n",
    "\n",
    "file1.to_csv('C:/Users/SS/Desktop/test1_predict.csv' ,header= True, index= False, encoding='UTF-8')\n",
    "\n",
    "file2.to_csv('C:/Users/SS/Desktop/test2_predict.csv' ,header= True, index= False, encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda31]",
   "language": "python",
   "name": "conda-env-Anaconda31-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
